{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "ThisPersonDoesNotExist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI2SwA8aYMZx"
      },
      "source": [
        "#Projet Mise en oeuvre d'un Réseau Antagoniste Génératif (GAN) pour la création de visages\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Marius Ferrieres, Bastien Garnier, Corentin Boudaud\n",
        "\n",
        "Projet de 4ème Année SAGI (Système Automatisés et Génie Informatique)\n",
        "\n",
        "Polytech Angers, 2021\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcKHyknMcwgc"
      },
      "source": [
        "!pip install google-api-python-client\n",
        "!pip install --version 3.1 oauth2client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im1PvBjXS5R6"
      },
      "source": [
        "# Pour faire des gifs\n",
        "!pip install -q imageio\n",
        "\n",
        "\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "!pip install PyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10iK8aOdTJuT",
        "outputId": "575b27eb-ad55-4d99-d082-0392e86de551"
      },
      "source": [
        "#Librairies nécessaires\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import imageio\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "import time\n",
        "import random\n",
        "import oauth2client.contrib\n",
        "from IPython import display\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOyE9VT7VDNC",
        "outputId": "7424ddee-a81f-412b-ecc9-3583455e88a7"
      },
      "source": [
        "# BLOCK ZIP-FILE\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "downloaded = drive.CreateFile({'id':\"0B7EVK8r0v71pZjFTYXZWM3FlRnM\"})\n",
        "downloaded.GetContentFile('img_align_celeba.zip')\n",
        "\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "with ZipFile('img_align_celeba.zip', 'r') as zipObj:\n",
        "  # Get a list of all archived file names from the zip\n",
        "  listOfFileNames = zipObj.namelist()\n",
        "  for fileName in listOfFileNames:\n",
        "    zipObj.extract(fileName)\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GGf-qUPgGf_"
      },
      "source": [
        "def getImages(number):\n",
        "  # BLOCK CREATION DE LA BDD\n",
        "  bddImg = []\n",
        "  for a in range(number):\n",
        "    randval = random.randint(1, len(listOfFileNames)) #200000\n",
        "    for b in listOfFileNames[randval:randval + 1]:\n",
        "      bddImg.append(mpl.image.imread(b))\n",
        "\n",
        "  train_img = []\n",
        "  for i in range(number):\n",
        "    train_img.append(bddImg[i][0:216,0:176,:])\n",
        "  train_img = np.array(train_img).astype('float32')\n",
        "  train_img = (train_img[:,:,:,:] - 127)/127\n",
        "\n",
        "  return train_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7sltsGeYOzl",
        "outputId": "84613395-84d4-4f07-a13b-1bae2d7545ea"
      },
      "source": [
        "# BLOCK CREATION DE LA BDD\n",
        "\"\"\"\n",
        "bddImg = []\n",
        "for a in range(0, 1000):\n",
        "  randval = random.randint(1, len(listOfFileNames)) #200000\n",
        "  for b in listOfFileNames[randval:randval + 1]:\n",
        "    bddImg.append(mpl.image.imread(b))\n",
        "print(\"Done\")\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmp4vdeF9vAE",
        "outputId": "1e213512-c547-4412-f7e2-0bddfddb19f3"
      },
      "source": [
        "# ALL FUNCTIONS\n",
        "\n",
        "def our_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(27*22*3, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Reshape((27, 22, 3)))\n",
        "    print(model.output_shape)\n",
        "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    print(model.output_shape)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    print(model.output_shape)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    print(model.output_shape)\n",
        "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    print(model.output_shape)\n",
        "    #assert model.output_shape == (None, 216, 176, 3)\n",
        "    return model\n",
        "\n",
        "def our_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[216, 176, 3]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "    return model\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    return\n",
        "\n",
        "\n",
        "def train(epochs, number):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    dataset = getImages(number)\n",
        "    train_step(dataset)\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "      generate_and_save_images(generator, epoch + 1, seed)\n",
        "    # Save the model every 100 epochs\n",
        "    if SAVE == 1:\n",
        "      if (epoch + 1) % 100 == 0:\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix, options=local_device_option)\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  return\n",
        "\n",
        "\"\"\"\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    for image_batch in dataset:\n",
        "      send = []\n",
        "      send.append(image_batch)\n",
        "      train_step(send)\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "      generate_and_save_images(generator, epoch + 1, seed)\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  return\n",
        "\"\"\"\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(np.squeeze(np.asarray(predictions[i])).astype('float32'))\n",
        "      #plt.imshow(predictions[i, :, :,2])\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "\n",
        "  plt.imshow(np.squeeze(np.asarray(predictions[0])).astype('float32'))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "  return\n",
        "\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB1gKrpShD1p",
        "outputId": "7b71c86d-2600-4b83-beb3-12361f9ffd3d"
      },
      "source": [
        "# BLOCK GENERATOR & DISCRIMINATOR\n",
        "generator = our_generator_model()\n",
        "noise = tf.random.normal([1, 100])\n",
        "\n",
        "discriminator = our_discriminator_model()\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 27, 22, 3)\n",
            "(None, 27, 22, 3)\n",
            "(None, 54, 44, 3)\n",
            "(None, 108, 88, 3)\n",
            "(None, 216, 176, 3)\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbe1SmmUMehs"
      },
      "source": [
        "# BLOCK FORMATAGE IMAGES\n",
        "\"\"\"\n",
        "train_img = []\n",
        "for i in range(0,len(bddImg)):\n",
        "  train_img.append(bddImg[i][0:216,0:176,:])\n",
        "train_img = np.array(train_img).astype('float32')\n",
        "train_img = (train_img[:,:,:,:] - 127)/127\n",
        "print(\"Done!\")\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_oqr_1PL6ot",
        "outputId": "a302b4eb-f68b-4764-966d-302747ed24eb"
      },
      "source": [
        "# BLOCK VARIABLES IMPORTANTES\n",
        "\"\"\"\n",
        "BUFFER_SIZE = train_img.shape[0]\n",
        "\"\"\"\n",
        "\n",
        "SAVE = 1\n",
        "\n",
        "BATCH_SIZE = 600\n",
        "\"\"\"\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_img).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\"\"\"\n",
        "\n",
        "EPOCHS = 1000\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btnp9Bm-YQrV",
        "outputId": "33f44d1b-dd90-486c-b65b-b6272699f51c"
      },
      "source": [
        "# BLOCK OPTIMISATION\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5clK-IXUu7F",
        "outputId": "a33a063c-53b3-4ad0-d1d8-4c686e73fdfe"
      },
      "source": [
        "#Sauvegarde dans drive des checkpoints\n",
        "\n",
        "# BLOCK CHECKPOINT\n",
        "checkpoint_dir = '/content/drive/MyDrive/Gan_Save/Checkpoints_Gan'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4zXzlodWn86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb6a649-6c20-410d-cdc1-b6d23e616952"
      },
      "source": [
        "#RESTORE THE CHECKPOINT\n",
        "#You have to upload the newest checkpoint in your directory\n",
        "#Then:   -Delete everything in your directory EXCEPT the file named \"checkpoints\"\n",
        "#        -Upload the new files\n",
        "#        -In this file you have to replace the number after \"ckpt\" to 1\n",
        "#        -Replace the number of both of the checkpoint files to 1\n",
        "#You can now run this part\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir), options=local_device_option).expect_partial()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3ca1daf1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFLC0D4TYeJk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "66539635-7489-40ee-840e-3cb5e9adb274"
      },
      "source": [
        "# BLOCK TRAINING\n",
        "#entraine le réseau\n",
        "\"\"\"\n",
        "train(train_dataset, EPOCHS)\n",
        "\"\"\"\n",
        "train(EPOCHS, BATCH_SIZE)\n",
        "#affiche le résultat final\n",
        "display_image(EPOCHS - 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 28 is 3.4003312587738037 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0a13036a0f18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#affiche le résultat final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdisplay_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-c93b932c1b91>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, number)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# Produce images for the GIF as we go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-d790cad0d8f6>\u001b[0m in \u001b[0;36mgetImages\u001b[0;34m(number)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mtrain_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbddImg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m216\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m176\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mtrain_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mtrain_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m127\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m127\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDI4I_bPgv9V"
      },
      "source": [
        "#Création GIF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSPPOm1Lx6ec"
      },
      "source": [
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWCeW-BFgo0P"
      },
      "source": [
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5HZpAadgtCS"
      },
      "source": [
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA4PdGocaQsg"
      },
      "source": [
        "###Intégration dans un site web"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdw3pClsaVkm"
      },
      "source": [
        "##Conclusion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ9lh1L7aXCu"
      },
      "source": [
        "##Remerciements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy8cV24_aa5-"
      },
      "source": [
        "##Sources\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxBwD4hdBTTt"
      },
      "source": [
        "### Vidéos Youtube :\n",
        "\n",
        "Arxiv Insights, Face editing with Generative Adversarial Networks: https://www.youtube.com/watch?v=dCKbRCUyop8&ab_channel=ArxivInsights\n",
        "\n",
        "Two Minutes Paper, StyleGAN2: Near-Perfect Human Face Synthesis...and More: https://www.youtube.com/watch?v=SWoravHhsUU&ab_channel=TwoMinutePapers\n",
        "\n",
        "Henry AI Labs, StyleGANv2 Explained! : https://www.youtube.com/watch?v=u8qPvzk0AfY&ab_channel=HenryAILabs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdeuGuw3BdaN"
      },
      "source": [
        "###Banques d'image :\n",
        "\n",
        "Large-scale CelebFaces Attributes (CelebA) Dataset : http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html (Plus de 10,000 personnes uniques et 200,000 photos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWwEuqZCBhIl"
      },
      "source": [
        "###Papiers scientifiques :\n",
        "\n",
        "*   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0KUnyPtBlyc"
      },
      "source": [
        "###Sites Web:\n",
        "\n",
        "*   Tutoriel Réseau Adversaire Génératif Convolutionnel Profond : https://www.tensorflow.org/tutorials/generative/dcgan\n",
        "*   What is a Generative Adversarial Network? : http://hunterheidenreich.com/blog/what-is-a-gan/"
      ]
    }
  ]
}